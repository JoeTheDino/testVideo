<html>
<head>
        <script>
            // getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
            if (window.location.protocol == "file:") {
                alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
            } else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:"){
                window.location.protocol = "https";
            }
        </script>

        <script src="./js/three.min.js"></script>
        <script src="./js/headtrackr.js"></script>
        <!--<script src="./js/tquery-bundle-require.js"></script>-->
        
</head>
<body>
        <canvas id="compare" width="320" height="240" style="display:none"></canvas>
        <video id="vid" autoplay="" loop="" height="240" style="position: absolute; top: 50px; z-index: 100001; display: block;"></video>
    <script>

        var scene, camera, renderer;
        var geometry, material, mesh;

        var videoInput = document.getElementById('vid');
        var canvasInput = document.getElementById('compare');

        init();
        animate();

        function init() {

            scene = new THREE.Scene();
            scene.fog = new THREE.Fog( 0x000000, 1, 5000 );

            camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 1, 10000 );
            camera.position.z = 1000;
            scene.add( camera );

            geometry = new THREE.BoxGeometry( 200, 200, 200 );
            material = new THREE.MeshBasicMaterial( { color: 0xff0000, wireframe: true } );

            mesh = new THREE.Mesh( geometry, material );
            scene.add( mesh );

            renderer = new THREE.WebGLRenderer();
            renderer.setSize( window.innerWidth, window.innerHeight );

            document.body.appendChild( renderer.domElement );

        }

        function animate() {

            requestAnimationFrame( animate );

            renderer.render( scene, camera );

        }

            init();
            animate();

        // video styling
          videoInput.style.position = 'absolute';
          videoInput.style.top = '50px';
          videoInput.style.zIndex = '100001';
          videoInput.style.display = 'block';
          
          // set up camera controller
          headtrackr.controllers.three.realisticAbsoluteCameraControl(camera, 27, [0,0,50], new THREE.Vector3(0,0,0), {damping : 0.5});
          
          // Face detection setup
          var htracker = new headtrackr.Tracker({altVideo : {ogv : "./media/capture5.ogv", mp4 : "./media/capture5.mp4"}, calcAngles : true, ui : false, headPosition : false, debug : debugOverlay});
          htracker.init(videoInput, canvasInput);
          htracker.start();
          
          document.addEventListener('headtrackingEvent', function(event) {
            scene.fog = new THREE.Fog( 0x000000, 1+(event.z*27), 3000+(event.z*27) );
          }, false);
    </script>

</body>
</html>